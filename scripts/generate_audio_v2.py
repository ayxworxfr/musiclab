#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆè„šæœ¬ v6.0 (FluidSynthå¢å¼ºç‰ˆ)
- ä½¿ç”¨FluidSynthé«˜å“è´¨éŸ³æºåº“
- æ·»åŠ éŸ³é¢‘è´¨é‡è¯„ä¼°ç³»ç»Ÿ
- æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆ
- æ·»åŠ é¢‘è°±åˆ†æå¯è§†åŒ–
- æ”¯æŒå¤šç§ä¹å™¨éŸ³è‰²ç”Ÿæˆï¼ˆé’¢ç´ã€ç”µé’¢ç´ã€é£ç´ã€å¼¦ä¹ã€å«éŸ³ã€é’Ÿç´ã€è´æ–¯ã€æ‹¨å¼¦ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
  python3 scripts/generate_audio.py                                    # é»˜è®¤ç”Ÿæˆé’¢ç´
  python3 scripts/generate_audio.py --instrument piano                 # ç”Ÿæˆé’¢ç´
  python3 scripts/generate_audio.py --instrument electric_piano        # ç”Ÿæˆç”µé’¢ç´
  python3 scripts/generate_audio.py --instrument organ                 # ç”Ÿæˆé£ç´
  python3 scripts/generate_audio.py --instrument strings               # ç”Ÿæˆå¼¦ä¹
  python3 scripts/generate_audio.py --instrument pad                   # ç”Ÿæˆå«éŸ³
  python3 scripts/generate_audio.py --instrument bell                  # ç”Ÿæˆé’Ÿç´
  python3 scripts/generate_audio.py --instrument bass                  # ç”Ÿæˆè´æ–¯
  python3 scripts/generate_audio.py --instrument pluck                 # ç”Ÿæˆæ‹¨å¼¦
  python3 scripts/generate_audio.py --parallel                         # å¹¶è¡Œæ¨¡å¼
  python3 scripts/generate_audio.py --analyze                          # ç”Ÿæˆåˆ†æå›¾è¡¨
  python3 scripts/generate_audio.py --list-instruments                 # åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„ä¹å™¨
  python3 scripts/generate_audio.py --download-soundfont               # ä¸‹è½½é«˜è´¨é‡éŸ³è‰²åº“

ä¾èµ–ï¼š
  pip3 install numpy scipy matplotlib librosa pyfluidsynth soundfile requests tqdm
  
  Windowsç”¨æˆ·è¿˜éœ€è¦å®‰è£…FluidSynthï¼š
  - ä¸‹è½½: https://github.com/FluidSynth/fluidsynth/releases
  - æ·»åŠ åˆ°PATHç¯å¢ƒå˜é‡
  
  macOSç”¨æˆ·:
  - brew install fluidsynth
  
  Linuxç”¨æˆ·:
  - sudo apt-get install fluidsynth
"""

import io
import os
import random
import shutil
import subprocess
import sys
import tempfile
import time
import warnings
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum, auto
from functools import partial
from multiprocessing import Pool, cpu_count
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import urllib.request

import matplotlib
import numpy as np

matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
from scipy import signal as scipy_signal
from scipy.io import wavfile
from scipy.ndimage import uniform_filter1d
from scipy.signal import butter, filtfilt

# å°è¯•å¯¼å…¥FluidSynth
try:
    import fluidsynth
    HAS_FLUIDSYNTH = True
except ImportError:
    HAS_FLUIDSYNTH = False
    print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°FluidSynthã€‚å°†ä½¿ç”¨å¢å¼ºé’¢ç´ç”Ÿæˆå™¨ä»£æ›¿ã€‚")
    print("   è¯·å®‰è£…FluidSynthè·å–æ›´å¥½çš„éŸ³é¢‘è´¨é‡: pip install pyfluidsynth")
    print("   Windowsç”¨æˆ·è¿˜éœ€è¦å®‰è£…FluidSynthå¹¶æ·»åŠ åˆ°PATH")

# å°è¯•å¯¼å…¥soundfile (æ¯”scipy.io.wavfileæ›´å¥½)
try:
    import soundfile as sf
    HAS_SOUNDFILE = True
except ImportError:
    HAS_SOUNDFILE = False

# å°è¯•å¯¼å…¥tqdm (ç”¨äºè¿›åº¦æ¡)
try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False
    print("æç¤º: å®‰è£…tqdmå¯ä»¥æ˜¾ç¤ºè¿›åº¦æ¡: pip install tqdm")

# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸ºUTF-8ç¼–ç ï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# å¿½ç•¥ matplotlib è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)


# ============================================================================
# å¸¸é‡å®šä¹‰
# ============================================================================

# MIDIéŸ³ç¬¦èŒƒå›´
MIDI_MIN = 21  # A0
MIDI_MAX = 108  # C8
MIDI_RANGE = range(MIDI_MIN, MIDI_MAX + 1)

# åˆ†ææ ·æœ¬éŸ³ç¬¦ï¼ˆè¦†ç›–ä¸åŒéŸ³åŸŸï¼‰
SAMPLE_NOTES_FOR_ANALYSIS = [21, 36, 48, 60, 72, 84, 96, 108]

# è´¨é‡é˜ˆå€¼
PITCH_ERROR_THRESHOLD_CENTS = 10  # éŸ³é«˜è¯¯å·®é˜ˆå€¼ï¼ˆéŸ³åˆ†ï¼‰
SNR_THRESHOLD_DB = 15  # ä¿¡å™ªæ¯”é˜ˆå€¼ï¼ˆåˆ†è´ï¼‰- å¯¹åˆæˆéŸ³é¢‘ä½¿ç”¨æ›´åˆç†çš„é˜ˆå€¼
THD_THRESHOLD_PERCENT = 5  # æ€»è°æ³¢å¤±çœŸé˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰

# æ ‡å‡†éŸ³é«˜
A4_FREQUENCY = 440.0
A4_MIDI = 69

# FluidSynth SoundFont URL
DEFAULT_SOUNDFONT_URL = "https://archive.org/download/fluidr3-gm-gs/FluidR3_GM.sf2"
DEFAULT_SOUNDFONT_FILENAME = "FluidR3_GM.sf2"


# ============================================================================
# é…ç½®æ¨¡å‹
# ============================================================================

@dataclass
class AudioConfig:
    """éŸ³é¢‘åŸºç¡€é…ç½®"""
    sample_rate: int = 44100
    bit_depth: int = 16
    channels: int = 1
    
    @property
    def max_amplitude(self) -> int:
        """æœ€å¤§æŒ¯å¹…å€¼"""
        return 2 ** (self.bit_depth - 1) - 1


@dataclass
class EnvelopeConfig:
    """ADSR åŒ…ç»œé…ç½®"""
    attack: float = 0.005    # èµ·éŸ³æ—¶é—´ï¼ˆç§’ï¼‰
    decay: float = 0.1       # è¡°å‡æ—¶é—´ï¼ˆç§’ï¼‰
    sustain: float = 0.6     # æŒç»­ç”µå¹³ (0-1)
    release: float = 0.8     # é‡Šæ”¾æ—¶é—´ï¼ˆç§’ï¼‰


@dataclass
class HarmonicConfig:
    """æ³›éŸ³é…ç½®"""
    harmonic_number: int     # æ³›éŸ³ç¼–å·ï¼ˆ1=åŸºé¢‘ï¼‰
    amplitude: float         # æŒ¯å¹… (0-1)
    decay_rate: float        # è¡°å‡é€Ÿåº¦


@dataclass
class EnhancedPianoConfig:
    """å¢å¼ºçš„é’¢ç´é…ç½®"""
    duration: float = 2.5
    envelope: EnvelopeConfig = field(default_factory=EnvelopeConfig)
    
    # æ›´ä¸°å¯Œçš„æ³›éŸ³ç»“æ„ï¼ˆåŸºäºçœŸå®é’¢ç´åˆ†æï¼‰
    harmonics: List[HarmonicConfig] = field(default_factory=lambda: [
        HarmonicConfig(1, 1.0, 2.0),     # åŸºé¢‘
        HarmonicConfig(2, 0.6, 2.5),     # äºŒæ¬¡æ³›éŸ³
        HarmonicConfig(3, 0.35, 3.0),     # ä¸‰æ¬¡æ³›éŸ³
        HarmonicConfig(4, 0.2, 3.5),
        HarmonicConfig(5, 0.12, 4.0),
        HarmonicConfig(6, 0.08, 4.5),
        HarmonicConfig(7, 0.05, 5.0),
        HarmonicConfig(8, 0.03, 5.5),
        HarmonicConfig(9, 0.02, 6.0),
        HarmonicConfig(10, 0.01, 6.5),
    ])
    
    # å¤±è°å‚æ•°
    inharmonic_detune: float = 1.003
    inharmonic_amplitude: float = 0.02
    
    # éŸ³æ¿å…±é¸£ï¼ˆä½é¢‘å…±æŒ¯ï¼‰
    soundboard_resonance: float = 0.05
    soundboard_freq_offset: float = 0.5  # åŠéŸ³
    
    # ç´å¼¦è€¦åˆï¼ˆç›¸é‚»å¼¦çš„å…±æŒ¯ï¼‰
    string_coupling: float = 0.03
    
    # æ·¡å…¥æ·¡å‡º
    fade_in: float = 0.002
    fade_out: float = 0.05


@dataclass
class MetronomeConfig:
    """èŠ‚æ‹å™¨é…ç½®"""
    duration: float = 0.08
    strong_beat_freq: float = 440
    weak_beat_freq: float = 660
    decay_rate: float = 40
    lowpass_cutoff: float = 3000


class EffectType(Enum):
    """æ•ˆæœéŸ³ç±»å‹"""
    CORRECT = "correct"
    WRONG = "wrong"
    COMPLETE = "complete"
    LEVEL_UP = "levelUp"


class InstrumentType(Enum):
    """ä¹å™¨ç±»å‹"""
    PIANO = auto()
    ELECTRIC_PIANO = auto()
    ORGAN = auto()
    STRINGS = auto()
    PAD = auto()
    BELL = auto()
    BASS = auto()
    PLUCK = auto()


# ============================================================================
# FluidSynthç›¸å…³é…ç½®
# ============================================================================

@dataclass
class FluidSynthConfig:
    """FluidSynthé…ç½®"""
    sample_rate: int = 44100
    soundfont_path: Optional[str] = None
    gain: float = 1.0
    reverb: bool = False
    chorus: bool = False
    
    # ä¹å™¨æ˜ å°„ï¼ˆMIDIç¨‹åºå·ï¼‰
    instrument_map: Dict[InstrumentType, int] = field(default_factory=lambda: {
        InstrumentType.PIANO: 0,          # å¤§é’¢ç´
        InstrumentType.ELECTRIC_PIANO: 4,  # ç”µé’¢ç´
        InstrumentType.ORGAN: 19,         # æ•™å ‚ç®¡é£ç´
        InstrumentType.STRINGS: 48,       # å¼¦ä¹åˆå¥
        InstrumentType.PAD: 89,           # æš–å«éŸ³
        InstrumentType.BELL: 9,           # é’Ÿç´
        InstrumentType.BASS: 32,          # åŸå£°è´æ–¯
        InstrumentType.PLUCK: 24,         # å°¼é¾™å¼¦å‰ä»–
    })
    
    # é¢å¤–çš„ä¹å™¨é€‰é¡¹
    alternative_instruments: Dict[InstrumentType, List[int]] = field(default_factory=lambda: {
        InstrumentType.PIANO: [1, 2, 3],          # äº®éŸ³é’¢ç´, å¤§é’¢ç´, èœ‚é¸£é’¢ç´
        InstrumentType.ELECTRIC_PIANO: [5, 6],    # ç”µé’¢ç´2, æ‹¨é”®ç´
        InstrumentType.ORGAN: [16, 17, 18],       # æŠ½ç®¡é£ç´, å’Œå£°é£ç´, æ‘‡æ»šé£ç´
        InstrumentType.STRINGS: [49, 50, 45],     # å¼¦ä¹åˆå¥2, åˆæˆå¼¦ä¹1, æ‹¨å¼¦
        InstrumentType.PAD: [88, 90, 91, 92],     # æ–°æ—¶ä»£å«éŸ³, å†°é›¨å«éŸ³, å£°éŸ³è½¨è¿¹, æ°´æ™¶
        InstrumentType.BELL: [10, 11, 112],       # éŸ³ä¹ç›’, é¢¤éŸ³ç´, é“ƒé“›
        InstrumentType.BASS: [33, 34, 35],        # æŒ‡å¼¹è´æ–¯, æ‹¨ç‰‡è´æ–¯, æ— å“è´æ–¯
        InstrumentType.PLUCK: [25, 26, 46],       # é’¢å¼¦å‰ä»–, çˆµå£«å‰ä»–, ç«–ç´
    })


# ============================================================================
# ä¹å™¨ç±»å‹æ˜ å°„å’Œå·¥å…·å‡½æ•°
# ============================================================================

# ä¹å™¨åç§°åˆ° InstrumentType çš„æ˜ å°„
INSTRUMENT_NAME_MAP = {
    'piano': InstrumentType.PIANO,
    'electric_piano': InstrumentType.ELECTRIC_PIANO,
    'organ': InstrumentType.ORGAN,
    'strings': InstrumentType.STRINGS,
    'pad': InstrumentType.PAD,
    'bell': InstrumentType.BELL,
    'bass': InstrumentType.BASS,
    'pluck': InstrumentType.PLUCK,
}

# ä¹å™¨ä¸­æ–‡åç§°
INSTRUMENT_NAMES_CN = {
    InstrumentType.PIANO: 'é’¢ç´',
    InstrumentType.ELECTRIC_PIANO: 'ç”µé’¢ç´',
    InstrumentType.ORGAN: 'é£ç´',
    InstrumentType.STRINGS: 'å¼¦ä¹',
    InstrumentType.PAD: 'åˆæˆå«éŸ³',
    InstrumentType.BELL: 'é’Ÿç´',
    InstrumentType.BASS: 'è´æ–¯',
    InstrumentType.PLUCK: 'æ‹¨å¼¦',
}

# ä¹å™¨é»˜è®¤æ—¶é•¿é…ç½®
INSTRUMENT_DURATION = {
    InstrumentType.PIANO: 2.5,
    InstrumentType.ELECTRIC_PIANO: 2.0,
    InstrumentType.ORGAN: 3.0,
    InstrumentType.STRINGS: 3.0,
    InstrumentType.PAD: 4.0,
    InstrumentType.BELL: 2.0,
    InstrumentType.BASS: 1.5,
    InstrumentType.PLUCK: 1.5,
}


def get_instrument_type(name: str) -> InstrumentType:
    """æ ¹æ®åç§°è·å–ä¹å™¨ç±»å‹"""
    name_lower = name.lower().replace('-', '_')
    if name_lower in INSTRUMENT_NAME_MAP:
        return INSTRUMENT_NAME_MAP[name_lower]
    raise ValueError(f"æœªçŸ¥çš„ä¹å™¨ç±»å‹: {name}ã€‚æ”¯æŒçš„ä¹å™¨: {', '.join(INSTRUMENT_NAME_MAP.keys())}")


def list_instruments():
    """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„ä¹å™¨"""
    print("=" * 70)
    print(" ğŸµ æ”¯æŒçš„ä¹å™¨ç±»å‹")
    print("=" * 70)
    print()
    for name, inst_type in INSTRUMENT_NAME_MAP.items():
        cn_name = INSTRUMENT_NAMES_CN[inst_type]
        duration = INSTRUMENT_DURATION[inst_type]
        print(f"  â€¢ {name:20s} ({cn_name:10s}) - é»˜è®¤æ—¶é•¿: {duration}s")
    print()
    print("=" * 70)


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def midi_to_frequency(midi: int) -> float:
    """MIDIéŸ³ç¬¦è½¬é¢‘ç‡"""
    return A4_FREQUENCY * (2.0 ** ((midi - A4_MIDI) / 12.0))


def midi_to_note_name(midi: int) -> str:
    """MIDIè½¬éŸ³ç¬¦åç§°"""
    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    octave = (midi // 12) - 1
    note = notes[midi % 12]
    return f"{note}{octave}"


def download_soundfont(output_dir: Path) -> Path:
    """ä¸‹è½½FluidSynth SoundFontæ–‡ä»¶"""
    output_dir.mkdir(parents=True, exist_ok=True)
    soundfont_path = output_dir / DEFAULT_SOUNDFONT_FILENAME
    
    if soundfont_path.exists():
        print(f"âœ“ å·²æ‰¾åˆ°SoundFontæ–‡ä»¶: {soundfont_path}")
        return soundfont_path
    
    print(f"â³ æ­£åœ¨ä¸‹è½½SoundFontæ–‡ä»¶ ({DEFAULT_SOUNDFONT_FILENAME})...")
    print(f"   æ¥æº: {DEFAULT_SOUNDFONT_URL}")
    
    try:
        if HAS_TQDM:
            import requests
            from tqdm import tqdm
            
            # ä½¿ç”¨tqdmæ˜¾ç¤ºä¸‹è½½è¿›åº¦
            response = requests.get(DEFAULT_SOUNDFONT_URL, stream=True)
            total_size = int(response.headers.get('content-length', 0))
            
            with open(soundfont_path, 'wb') as f, tqdm(
                desc="ä¸‹è½½ä¸­",
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as bar:
                for data in response.iter_content(chunk_size=1024):
                    size = f.write(data)
                    bar.update(size)
        else:
            # æ²¡æœ‰tqdmæ—¶ä½¿ç”¨åŸºæœ¬çš„urllib
            urllib.request.urlretrieve(DEFAULT_SOUNDFONT_URL, soundfont_path)
        
        print(f"âœ“ SoundFontæ–‡ä»¶ä¸‹è½½å®Œæˆ: {soundfont_path}")
        return soundfont_path
    
    except Exception as e:
        print(f"âŒ ä¸‹è½½SoundFontæ–‡ä»¶å¤±è´¥: {e}")
        print("   è¯·æ‰‹åŠ¨ä¸‹è½½SoundFontæ–‡ä»¶å¹¶æ”¾ç½®åœ¨ä»¥ä¸‹ä½ç½®:")
        print(f"   {soundfont_path}")
        raise


def find_soundfont() -> Optional[Path]:
    """æŸ¥æ‰¾ç³»ç»Ÿä¸­çš„SoundFontæ–‡ä»¶"""
    # å¸¸è§çš„SoundFontæ–‡ä»¶è·¯å¾„
    common_paths = [
        # å½“å‰ç›®å½•
        Path.cwd() / "FluidR3_GM.sf2",
        Path.cwd() / "soundfonts" / "FluidR3_GM.sf2",
        
        # ç”¨æˆ·ç›®å½•
        Path.home() / "FluidR3_GM.sf2",
        Path.home() / "soundfonts" / "FluidR3_GM.sf2",
        Path.home() / ".fluidsynth" / "FluidR3_GM.sf2",
        Path.home() / ".local" / "share" / "soundfonts" / "FluidR3_GM.sf2",
        
        # Windowsè·¯å¾„
        Path("C:/Program Files/FluidSynth/share/soundfonts/FluidR3_GM.sf2"),
        Path("C:/Program Files (x86)/FluidSynth/share/soundfonts/FluidR3_GM.sf2"),
        
        # macOSè·¯å¾„
        Path("/usr/local/share/soundfonts/FluidR3_GM.sf2"),
        Path("/usr/local/share/fluidsynth/FluidR3_GM.sf2"),
        
        # Linuxè·¯å¾„
        Path("/usr/share/sounds/sf2/FluidR3_GM.sf2"),
        Path("/usr/share/soundfonts/FluidR3_GM.sf2"),
    ]
    
    # æ£€æŸ¥å¸¸è§è·¯å¾„
    for path in common_paths:
        if path.exists():
            return path
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if 'SOUNDFONT' in os.environ and Path(os.environ['SOUNDFONT']).exists():
        return Path(os.environ['SOUNDFONT'])
    
    return None


# ============================================================================
# éŸ³é¢‘å¤„ç†å·¥å…·
# ============================================================================

class AudioProcessor:
    """éŸ³é¢‘å¤„ç†å·¥å…·ç±»"""
    
    @staticmethod
    def apply_fade(audio: np.ndarray, fade_in_samples: int, fade_out_samples: int) -> np.ndarray:
        """åº”ç”¨æ·¡å…¥æ·¡å‡º"""
        result = audio.copy().astype(np.float64)
        
        if fade_in_samples > 0:
            fade_in = np.linspace(0, 1, fade_in_samples)
            result[:fade_in_samples] *= fade_in
        
        if fade_out_samples > 0:
            fade_out = np.linspace(1, 0, fade_out_samples)
            result[-fade_out_samples:] *= fade_out
        
        return result
    
    @staticmethod
    def lowpass_filter(audio: np.ndarray, cutoff: float, sample_rate: int) -> np.ndarray:
        """ä½é€šæ»¤æ³¢å™¨"""
        nyquist = sample_rate / 2
        normalized_cutoff = min(cutoff / nyquist, 0.99)
        b, a = butter(4, normalized_cutoff, btype='low')
        return filtfilt(b, a, audio)
    
    @staticmethod
    def normalize(audio: np.ndarray, target_level: float = 0.9) -> np.ndarray:
        """å½’ä¸€åŒ–éŸ³é¢‘"""
        max_val = np.max(np.abs(audio))
        if max_val > 0:
            audio = audio / max_val * target_level
        return audio
    
    @staticmethod
    def to_int16(audio: np.ndarray) -> np.ndarray:
        """è½¬æ¢ä¸º16ä½æ•´æ•°"""
        return (audio * 32767).astype(np.int16)
    
    @staticmethod
    def mix(audios: List[np.ndarray], 
            volumes: Optional[List[float]] = None,
            use_smart_mixing: bool = True) -> np.ndarray:
        """
        æ™ºèƒ½æ··åˆå¤šä¸ªéŸ³é¢‘
        
        ä½¿ç”¨RMSå½’ä¸€åŒ–è€Œä¸æ˜¯å³°å€¼å½’ä¸€åŒ–ï¼Œé¿å…å¤šéŸ³å åŠ æ—¶çš„å‰Šæ³¢é—®é¢˜
        è¿™æ˜¯é’¢ç´è½¯ä»¶èƒ½å¤ŸåŒæ—¶æ’­æ”¾å¤šä¸ªéŸ³ç¬¦çš„å…³é”®æŠ€æœ¯
        
        Args:
            audios: éŸ³é¢‘æ•°ç»„åˆ—è¡¨
            volumes: éŸ³é‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            use_smart_mixing: æ˜¯å¦ä½¿ç”¨æ™ºèƒ½æ··éŸ³ï¼ˆRMSå½’ä¸€åŒ– + è½¯å‰Šæ³¢ï¼‰
        
        Returns:
            æ··åˆåçš„éŸ³é¢‘
        """
        if not audios:
            return np.array([], dtype=np.float64)
        
        if len(audios) == 1:
            return audios[0]
        
        if volumes is None:
            volumes = [1.0] * len(audios)
        
        # å¯¹é½é•¿åº¦
        max_length = max(len(a) for a in audios)
        aligned_audios = []
        
        for audio, vol in zip(audios, volumes):
            if len(audio) < max_length:
                padded = np.pad(audio, (0, max_length - len(audio)), mode='constant')
                aligned_audios.append(padded.astype(np.float64) * vol)
            else:
                aligned_audios.append(audio[:max_length].astype(np.float64) * vol)
        
        # ç®€å•ç›¸åŠ 
        mixed = np.sum(aligned_audios, axis=0)
        
        if use_smart_mixing:
            # å…³é”®ï¼šä½¿ç”¨RMSå½’ä¸€åŒ–ï¼ˆâˆšnè§„åˆ™ï¼‰
            # è¿™ç¡®ä¿Nä¸ªéŸ³ç¬¦æ··åˆæ—¶ï¼Œæ€»éŸ³é‡ä¸ä¼šçº¿æ€§å¢é•¿ï¼Œè€Œæ˜¯æŒ‰âˆšNå¢é•¿
            # è¿™æ˜¯ä¸“ä¸šéŸ³é¢‘è½¯ä»¶çš„æ ‡å‡†åšæ³•
            num_notes = len(aligned_audios)
            mixed = mixed / np.sqrt(num_notes)
            
            # åº”ç”¨è½¯å‰Šæ³¢é˜²æ­¢ç¡¬å‰Šæ³¢å¤±çœŸ
            mixed = AudioProcessor.soft_clip(mixed, threshold=0.9)
        
        return mixed
    
    @staticmethod
    def soft_clip(audio: np.ndarray, threshold: float = 0.9) -> np.ndarray:
        """
        è½¯å‰Šæ³¢ - é˜²æ­¢ç¡¬å‰Šæ³¢å¤±çœŸ
        
        å½“éŸ³é¢‘è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œä½¿ç”¨tanhå‡½æ•°å¹³æ»‘å‹ç¼©ï¼Œè€Œä¸æ˜¯ç¡¬æˆªæ–­
        """
        result = audio.copy()
        mask = np.abs(result) > threshold
        if np.any(mask):
            result[mask] = threshold * np.sign(result[mask]) * np.tanh(
                np.abs(result[mask]) / threshold
            )
        return result
    
    @staticmethod
    def apply_phase_randomization(audio: np.ndarray, 
                                   frequency: float,
                                   sample_rate: int = 44100) -> np.ndarray:
        """
        åº”ç”¨ç›¸ä½éšæœºåŒ–
        
        å¯¹äºé¢„å½•çš„éŸ³é¢‘ï¼Œé€šè¿‡è½»å¾®çš„æ—¶é—´åç§»æ¥é¿å…ç›¸ä½å¯¹é½é—®é¢˜
        è¿™æ˜¯é’¢ç´è½¯ä»¶å¤„ç†å¤šéŸ³å åŠ çš„å…³é”®æŠ€æœ¯ä¹‹ä¸€
        """
        # éšæœºç›¸ä½åç§»ï¼ˆ0-2Ï€ï¼‰
        phase_offset = np.random.uniform(0, 2 * np.pi)
        
        # é€šè¿‡FFTåº”ç”¨ç›¸ä½åç§»
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/sample_rate)
        
        # åªåœ¨åŸºé¢‘é™„è¿‘åº”ç”¨ç›¸ä½åç§»
        fundamental_idx = np.argmin(np.abs(freqs - frequency))
        window_size = max(10, len(fft) // 100)  # å½±å“èŒƒå›´
        
        start_idx = max(0, fundamental_idx - window_size)
        end_idx = min(len(fft), fundamental_idx + window_size)
        
        # åº”ç”¨ç›¸ä½åç§»
        fft[start_idx:end_idx] *= np.exp(1j * phase_offset)
        
        # è½¬æ¢å›æ—¶åŸŸ
        result = np.fft.irfft(fft, len(audio))
        return result.astype(np.float64)


class EnvelopeGenerator:
    """åŒ…ç»œç”Ÿæˆå™¨"""
    
    @staticmethod
    def adsr(num_samples: int, sample_rate: int, config: EnvelopeConfig) -> np.ndarray:
        """ç”ŸæˆADSRåŒ…ç»œ"""
        attack_samples = int(config.attack * sample_rate)
        decay_samples = int(config.decay * sample_rate)
        release_samples = int(config.release * sample_rate)
        sustain_samples = max(0, num_samples - attack_samples - decay_samples - release_samples)
        
        if sustain_samples <= 0:
            sustain_samples = 0
            release_samples = num_samples - attack_samples - decay_samples
        
        envelope = np.zeros(num_samples)
        pos = 0
        
        # Attack
        if attack_samples > 0:
            envelope[pos:pos + attack_samples] = np.linspace(0, 1, attack_samples)
            pos += attack_samples
        
        # Decay
        if decay_samples > 0 and pos + decay_samples <= num_samples:
            envelope[pos:pos + decay_samples] = np.linspace(1, config.sustain, decay_samples)
            pos += decay_samples
        
        # Sustain (with slow decay)
        if sustain_samples > 0 and pos + sustain_samples <= num_samples:
            envelope[pos:pos + sustain_samples] = config.sustain * np.exp(
                -0.5 * np.linspace(0, 1, sustain_samples)
            )
            pos += sustain_samples
        
        # Release
        if release_samples > 0 and pos < num_samples:
            remaining = num_samples - pos
            actual_release = min(remaining, release_samples)
            start_level = envelope[pos - 1] if pos > 0 else config.sustain
            envelope[pos:pos + actual_release] = start_level * np.exp(
                -3 * np.linspace(0, 1, actual_release)
            )
        
        return envelope
    
    @staticmethod
    def percussive(num_samples: int, sample_rate: int, attack_ms: float = 1, decay_rate: float = 40) -> np.ndarray:
        """æ‰“å‡»ä¹åŒ…ç»œ"""
        attack = int(attack_ms * sample_rate / 1000)
        decay = num_samples - attack
        
        envelope = np.zeros(num_samples)
        envelope[:attack] = np.linspace(0, 1, attack)
        envelope[attack:] = np.exp(-decay_rate * np.linspace(0, 1, decay))
        
        return envelope


# ============================================================================
# éŸ³é¢‘è´¨é‡åˆ†æå™¨
# ============================================================================

class AudioQualityAnalyzer:
    """éŸ³é¢‘è´¨é‡åˆ†æå™¨"""
    
    @staticmethod
    def analyze_spectrum(audio: np.ndarray, sr: int, midi_note: int) -> Dict:
        """åˆ†æé¢‘è°±ï¼ŒéªŒè¯éŸ³é«˜å‡†ç¡®æ€§"""
        # FFTåˆ†æ
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/sr)
        magnitude = np.abs(fft)
        
        # æ‰¾åˆ°ä¸»é¢‘ç‡ï¼ˆå¿½ç•¥ç›´æµåˆ†é‡ï¼‰
        magnitude[0] = 0
        peak_idx = np.argmax(magnitude)
        detected_freq = freqs[peak_idx]
        
        # æœŸæœ›é¢‘ç‡
        expected_freq = midi_to_frequency(midi_note)
        
        # è®¡ç®—è¯¯å·®ï¼ˆéŸ³åˆ†ï¼‰
        if detected_freq > 0:
            error_cents = 1200 * np.log2(detected_freq / expected_freq)
        else:
            error_cents = 999
        
        return {
            'detected_freq': detected_freq,
            'expected_freq': expected_freq,
            'error_cents': error_cents,
            'is_accurate': abs(error_cents) < PITCH_ERROR_THRESHOLD_CENTS
        }
    
    @staticmethod
    def calculate_snr(audio: np.ndarray, sr: int = 44100) -> float:
        """è®¡ç®—ä¿¡å™ªæ¯”ï¼ˆSignal-to-Noise Ratioï¼‰
        
        æ”¹è¿›çš„è®¡ç®—æ–¹æ³•ï¼š
        - ä½¿ç”¨é¢‘è°±åˆ†æï¼Œè®¡ç®—åŸºé¢‘åŠå…¶è°æ³¢çš„èƒ½é‡ï¼ˆä¿¡å·ï¼‰
        - è®¡ç®—éè°æ³¢é¢‘ç‡çš„èƒ½é‡ï¼ˆå™ªå£°ï¼‰
        - å¯¹äºåˆæˆéŸ³é¢‘ï¼Œè¿™ç§æ–¹æ³•æ›´å‡†ç¡®
        """
        # ä½¿ç”¨FFTè¿›è¡Œé¢‘è°±åˆ†æ
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/sr)
        magnitude = np.abs(fft)
        
        # æ‰¾åˆ°ä¸»å³°ï¼ˆåŸºé¢‘ï¼‰
        magnitude_copy = magnitude.copy()
        magnitude_copy[0] = 0  # å¿½ç•¥ç›´æµåˆ†é‡
        peak_idx = np.argmax(magnitude_copy)
        peak_freq = freqs[peak_idx]
        
        # è®¡ç®—ä¿¡å·åŠŸç‡ï¼ˆåŸºé¢‘åŠå…¶å‰8ä¸ªè°æ³¢çš„èƒ½é‡ï¼‰
        signal_power = 0
        for n in range(1, 9):
            harmonic_freq = peak_freq * n
            if harmonic_freq < freqs[-1]:
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„é¢‘ç‚¹
                idx = np.argmin(np.abs(freqs - harmonic_freq))
                signal_power += magnitude[idx] ** 2
        
        # è®¡ç®—å™ªå£°åŠŸç‡ï¼ˆæ€»åŠŸç‡å‡å»ä¿¡å·åŠŸç‡ï¼‰
        total_power = np.sum(magnitude ** 2)
        noise_power = total_power - signal_power
        
        # å¦‚æœå™ªå£°åŠŸç‡å¤ªå°ï¼Œè¯´æ˜ä¿¡å·è´¨é‡å¾ˆå¥½
        if noise_power < 1e-10 or signal_power < 1e-10:
            return 100.0
        
        # è®¡ç®—SNRï¼ˆåˆ†è´ï¼‰
        snr = 10 * np.log10(signal_power / noise_power)
        return snr
    
    @staticmethod
    def calculate_thd(audio: np.ndarray, sr: int, fundamental_freq: float) -> float:
        """è®¡ç®—æ€»è°æ³¢å¤±çœŸï¼ˆTotal Harmonic Distortionï¼‰"""
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/sr)
        magnitude = np.abs(fft)
        
        # åŸºé¢‘èƒ½é‡
        fundamental_idx = np.argmin(np.abs(freqs - fundamental_freq))
        fundamental_power = magnitude[fundamental_idx] ** 2
        
        # è°æ³¢èƒ½é‡ï¼ˆ2-8æ¬¡è°æ³¢ï¼‰
        harmonic_power = 0
        for n in range(2, 9):
            harmonic_freq = fundamental_freq * n
            if harmonic_freq < sr / 2:
                harmonic_idx = np.argmin(np.abs(freqs - harmonic_freq))
                harmonic_power += magnitude[harmonic_idx] ** 2
        
        if fundamental_power > 0:
            thd = np.sqrt(harmonic_power / fundamental_power) * 100
        else:
            thd = 0
        
        return thd


# ============================================================================
# éŸ³é¢‘å¯è§†åŒ–å·¥å…·
# ============================================================================

class AudioVisualizer:
    """éŸ³é¢‘å¯è§†åŒ–å·¥å…·"""
    
    @staticmethod
    def plot_analysis(audio: np.ndarray, sr: int, midi: int, output_path: Path):
        """ç”Ÿæˆå®Œæ•´çš„éŸ³é¢‘åˆ†æå›¾è¡¨"""
        fig = plt.figure(figsize=(14, 10))
        gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)
        
        # 1. æ³¢å½¢å›¾
        ax1 = fig.add_subplot(gs[0, :])
        t = np.linspace(0, len(audio)/sr, len(audio))
        ax1.plot(t, audio, linewidth=0.5, color='#2E86AB')
        ax1.set_title(f'Waveform - MIDI {midi} ({midi_to_note_name(midi)})', 
                      fontsize=12, fontweight='bold')
        ax1.set_xlabel('Time (s)')
        ax1.set_ylabel('Amplitude')
        ax1.grid(True, alpha=0.3)
        ax1.set_xlim(0, min(1.0, len(audio)/sr))  # åªæ˜¾ç¤ºå‰1ç§’
        
        # 2. é¢‘è°±å›¾ï¼ˆFFTï¼‰
        ax2 = fig.add_subplot(gs[1, 0])
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/sr)
        magnitude_db = 20 * np.log10(np.abs(fft) + 1e-10)
        
        ax2.plot(freqs, magnitude_db, linewidth=0.8, color='#A23B72')
        ax2.set_title('Frequency Spectrum', fontsize=11, fontweight='bold')
        ax2.set_xlabel('Frequency (Hz)')
        ax2.set_ylabel('Magnitude (dB)')
        ax2.set_xlim(0, 5000)
        ax2.grid(True, alpha=0.3)
        
        # æ ‡è®°ç†è®ºæ³›éŸ³ä½ç½®
        fundamental = midi_to_frequency(midi)
        for n in range(1, 9):
            harmonic_freq = fundamental * n
            if harmonic_freq < 5000:
                ax2.axvline(harmonic_freq, color='#F18F01', alpha=0.5, 
                           linestyle='--', linewidth=1)
                if n == 1:
                    ax2.text(harmonic_freq, ax2.get_ylim()[1]*0.95, 'Fâ‚€', 
                            ha='center', fontsize=8)
        
        # 3. å£°è°±å›¾ï¼ˆSpectrogramï¼‰
        ax3 = fig.add_subplot(gs[1, 1])
        f, t_spec, Sxx = scipy_signal.spectrogram(audio, sr, nperseg=1024)
        im = ax3.pcolormesh(t_spec, f, 10 * np.log10(Sxx + 1e-10), 
                            shading='gouraud', cmap='viridis')
        ax3.set_title('Spectrogram', fontsize=11, fontweight='bold')
        ax3.set_ylabel('Frequency (Hz)')
        ax3.set_xlabel('Time (s)')
        ax3.set_ylim(0, 5000)
        plt.colorbar(im, ax=ax3, label='dB')
        
        # 4. åŒ…ç»œå›¾
        ax4 = fig.add_subplot(gs[2, 0])
        envelope = np.abs(audio)
        smooth_envelope = uniform_filter1d(envelope, size=int(sr*0.01))
        ax4.plot(t, smooth_envelope, linewidth=1.5, color='#C73E1D')
        ax4.fill_between(t, smooth_envelope, alpha=0.3, color='#C73E1D')
        ax4.set_title('Envelope', fontsize=11, fontweight='bold')
        ax4.set_xlabel('Time (s)')
        ax4.set_ylabel('Amplitude')
        ax4.grid(True, alpha=0.3)
        ax4.set_xlim(0, len(audio)/sr)
        
        # 5. è´¨é‡æŒ‡æ ‡
        ax5 = fig.add_subplot(gs[2, 1])
        ax5.axis('off')
        
        analyzer = AudioQualityAnalyzer()
        spectrum_result = analyzer.analyze_spectrum(audio, sr, midi)
        snr = analyzer.calculate_snr(audio, sr)
        thd = analyzer.calculate_thd(audio, sr, fundamental)
        
        info_text = f"""
Quality Metrics:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MIDI Note: {midi} ({midi_to_note_name(midi)})
Fundamental: {fundamental:.2f} Hz
Detected: {spectrum_result['detected_freq']:.2f} Hz
Pitch Error: {spectrum_result['error_cents']:.2f} cents
Accuracy: {'âœ“ PASS' if spectrum_result['is_accurate'] else 'âœ— FAIL'}

SNR: {snr:.1f} dB {'âœ“' if snr > SNR_THRESHOLD_DB else 'âœ—'}
THD: {thd:.2f}% {'âœ“' if thd < THD_THRESHOLD_PERCENT else 'âœ—'}

Duration: {len(audio)/sr:.2f} s
Sample Rate: {sr} Hz
        """
        
        ax5.text(0.1, 0.5, info_text, fontsize=10, family='monospace',
                verticalalignment='center')
        
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()


# ============================================================================
# FluidSynthéŸ³é¢‘ç”Ÿæˆå™¨
# ============================================================================

class FluidSynthGenerator:
    """FluidSynthéŸ³é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self, config: AudioConfig, fs_config: FluidSynthConfig):
        """
        åˆå§‹åŒ–FluidSynthç”Ÿæˆå™¨
        
        Args:
            config: éŸ³é¢‘é…ç½®
            fs_config: FluidSynthé…ç½®
        """
        self.config = config
        self.fs_config = fs_config
        self.processor = AudioProcessor()
        
        # æ£€æŸ¥FluidSynthå¯ç”¨æ€§
        if not HAS_FLUIDSYNTH:
            raise ImportError("æœªå®‰è£…FluidSynthã€‚è¯·ä½¿ç”¨pip install pyfluidsynthå®‰è£…")
        
        # åˆå§‹åŒ–FluidSynth
        self.fs = fluidsynth.Synth(gain=fs_config.gain)
        
        # è®¾ç½®é‡‡æ ·ç‡
        self.fs.setting("synth.sample-rate", fs_config.sample_rate)
        
        # è®¾ç½®æ··éŸ³é€šé“æ•° (1=å•å£°é“ï¼Œ2=ç«‹ä½“å£°)
        self.fs.setting("synth.audio-channels", config.channels)
        self.fs.setting("synth.audio-groups", config.channels)
        
        # éŸ³è´¨è®¾ç½®
        self.fs.setting("synth.chorus.active", 1 if fs_config.chorus else 0)
        self.fs.setting("synth.reverb.active", 1 if fs_config.reverb else 0)
        
        # åŠ è½½SoundFont
        self.sfid = self.fs.sfload(str(fs_config.soundfont_path), update_midi_preset=1)
        if self.sfid == -1:
            raise RuntimeError(f"æ— æ³•åŠ è½½SoundFontæ–‡ä»¶: {fs_config.soundfont_path}")
        
        # é€‰æ‹©é€šç”¨MIDIè¾“å‡º
        self.fs.setting("synth.midi-bank-select", "gm")
        
        # åˆå§‹åŒ–éŸ³é¢‘é©±åŠ¨
        self.fs.start(driver="file", file="unused")
    
    def generate_note(self, 
                      instrument_type: InstrumentType, 
                      midi_number: int, 
                      velocity: float = 0.8, 
                      duration: float = None) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆå•ä¸ªéŸ³ç¬¦"""
        # è·å–MIDIç¨‹åºå·
        program = self.fs_config.instrument_map[instrument_type]
        
        # å¦‚æœæœªæŒ‡å®šæŒç»­æ—¶é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if duration is None:
            duration = INSTRUMENT_DURATION[instrument_type]
        
        # è®¡ç®—æ ·æœ¬æ•°
        num_samples = int(self.config.sample_rate * duration)
        
        # é€‰æ‹©é€šé“å’Œä¹å™¨
        channel = 0
        self.fs.program_select(channel, self.sfid, 0, program)
        
        # è½¬æ¢velocity (0.0-1.0) åˆ° MIDI velocity (0-127)
        midi_velocity = min(127, max(1, int(velocity * 127)))
        
        # æŒ‰ä¸‹éŸ³ç¬¦
        self.fs.noteon(channel, midi_number, midi_velocity)
        
        # æ¸²æŸ“éŸ³é¢‘
        audio = np.zeros(num_samples, dtype=np.float32)
        self.fs.write_s16_stereo(audio)
        
        # é‡Šæ”¾éŸ³ç¬¦
        self.fs.noteoff(channel, midi_number)
        
        # ç­‰å¾…é‡ŠéŸ³å®Œæˆ
        release_samples = int(self.config.sample_rate * 0.1)  # 100msé¢å¤–é‡Šæ”¾æ—¶é—´
        release_audio = np.zeros(release_samples, dtype=np.float32)
        self.fs.write_s16_stereo(release_audio)
        
        # åˆå¹¶ä¸»éŸ³é¢‘å’Œé‡Šæ”¾éŸ³é¢‘
        audio = np.concatenate([audio, release_audio])
        
        # å¦‚æœæ˜¯å•å£°é“ï¼Œå–å·¦å£°é“
        if self.config.channels == 1:
            # FluidSynthä»¥äº¤é”™æ–¹å¼è¾“å‡ºç«‹ä½“å£°
            audio = audio[::2]
        
        # åº”ç”¨æ·¡å‡ºä»¥æ¶ˆé™¤å¯èƒ½çš„çˆ†éŸ³
        fade_out_samples = int(0.01 * self.config.sample_rate)  # 10msæ·¡å‡º
        audio = self.processor.apply_fade(audio, 0, fade_out_samples)
        
        # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸ºint16
        audio = self.processor.normalize(audio, 0.95)
        audio = self.processor.to_int16(audio)
        
        return audio, self.config.sample_rate
    
    def cleanup(self):
        """æ¸…ç†FluidSynthèµ„æº"""
        if hasattr(self, 'fs'):
            self.fs.delete()


# ============================================================================
# éŸ³é¢‘ç”Ÿæˆå™¨åŸºç±»
# ============================================================================

class AudioGenerator(ABC):
    """éŸ³é¢‘ç”Ÿæˆå™¨æŠ½è±¡åŸºç±»"""
    
    def __init__(self, config: AudioConfig):
        self.config = config
        self.processor = AudioProcessor()
    
    @abstractmethod
    def generate(self) -> Tuple[np.ndarray, int]:
        """ç”ŸæˆéŸ³é¢‘æ•°æ®"""
        pass
    
    def _midi_to_frequency(self, midi: int) -> float:
        """MIDIéŸ³ç¬¦è½¬é¢‘ç‡"""
        return midi_to_frequency(midi)
    
    def _create_time_array(self, duration: float) -> np.ndarray:
        """åˆ›å»ºæ—¶é—´æ•°ç»„"""
        num_samples = int(self.config.sample_rate * duration)
        return np.linspace(0, duration, num_samples)


# ============================================================================
# å¢å¼ºé’¢ç´ç”Ÿæˆå™¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
# ============================================================================

class EnhancedPianoGenerator(AudioGenerator):
    """å¢å¼ºçš„é’¢ç´éŸ³è‰²ç”Ÿæˆå™¨ï¼ˆç‰©ç†å»ºæ¨¡ï¼‰"""
    
    def __init__(self, config: AudioConfig, piano_config: EnhancedPianoConfig):
        super().__init__(config)
        self.piano_config = piano_config
    
    def generate(self, midi_number: int, velocity: float = 0.8, duration: float = None) -> Tuple[np.ndarray, int]:
        """
        ç”Ÿæˆé’¢ç´éŸ³ç¬¦
        
        Args:
            midi_number: MIDIéŸ³ç¬¦ç¼–å·
            velocity: åŠ›åº¦ï¼ˆ0.0-1.0ï¼‰ï¼Œå½“å‰å®ç°ä¸­æœªä½¿ç”¨ï¼Œä¿ç•™ä»¥å…¼å®¹æ¥å£
            duration: æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        """
        # ä½¿ç”¨ä¼ å…¥çš„durationæˆ–é…ç½®ä¸­çš„é»˜è®¤å€¼
        note_duration = duration if duration is not None else self.piano_config.duration
        
        frequency = self._midi_to_frequency(midi_number)
        t = self._create_time_array(note_duration)
        num_samples = len(t)
        
        # ç”Ÿæˆæ³›éŸ³å åŠ 
        audio = self._generate_harmonics(t, frequency)
        
        # æ·»åŠ è½»å¾®å¤±è°
        audio += self._generate_inharmonic(t, frequency)
        
        # æ·»åŠ éŸ³æ¿å…±é¸£
        audio += self._add_soundboard_resonance(t, frequency)
        
        # æ·»åŠ ç´å¼¦è€¦åˆ
        audio += self._add_string_coupling(t, frequency)
        
        # æ ¹æ®éŸ³é«˜è°ƒæ•´åŒ…ç»œ
        envelope_config = self._adjust_envelope_for_pitch(midi_number)
        envelope = EnvelopeGenerator.adsr(num_samples, self.config.sample_rate, envelope_config)
        audio *= envelope
        
        # åŠ¨æ€ä½é€šæ»¤æ³¢
        cutoff = self._calculate_dynamic_cutoff(midi_number, frequency)
        audio = self.processor.lowpass_filter(audio, cutoff, self.config.sample_rate)
        
        # åº”ç”¨æ·¡å…¥æ·¡å‡ºï¼ˆé˜²æ­¢çˆ†éŸ³ï¼‰
        fade_in_samples = int(self.piano_config.fade_in * self.config.sample_rate)
        fade_out_samples = int(self.piano_config.fade_out * self.config.sample_rate)
        audio = self.processor.apply_fade(audio, fade_in_samples, fade_out_samples)
        
        # å½’ä¸€åŒ–
        audio = self.processor.normalize(audio, 0.95)
        
        # ç›¸ä½éšæœºåŒ–ï¼ˆå¯é€‰ï¼Œå¯¹äºå¤šéŸ³å åŠ å¾ˆæœ‰ç”¨ï¼‰
        audio = self.processor.apply_phase_randomization(audio, frequency, self.config.sample_rate)
        
        # è½¬æ¢ä¸º16ä½æ•´æ•°
        audio_int16 = self.processor.to_int16(audio)
        
        return audio_int16, self.config.sample_rate
    
    def _generate_harmonics(self, t: np.ndarray, frequency: float) -> np.ndarray:
        """ç”Ÿæˆæ³›éŸ³å åŠ """
        audio = np.zeros_like(t, dtype=np.float64)
        
        for harmonic in self.piano_config.harmonics:
            harmonic_freq = frequency * harmonic.harmonic_number
            if harmonic_freq < self.config.sample_rate / 2:  # é˜²æ­¢å¥ˆå¥æ–¯ç‰¹é¢‘ç‡ä»¥ä¸Šçš„æ³›éŸ³
                decay_factor = np.exp(-harmonic.decay_rate * t)
                audio += harmonic.amplitude * decay_factor * np.sin(2 * np.pi * harmonic_freq * t)
        
        return audio
    
    def _generate_inharmonic(self, t: np.ndarray, frequency: float) -> np.ndarray:
        """ç”Ÿæˆè½»å¾®å¤±è°çš„éŸ³è‰²"""
        audio = np.zeros_like(t, dtype=np.float64)
        
        # è½»å¾®å¤±è°çš„é¢‘ç‡ï¼ˆéæ•´æ•°å€ï¼‰
        inharmonic_freq = frequency * self.piano_config.inharmonic_detune
        
        # éšæ—¶é—´å¿«é€Ÿè¡°å‡çš„å¤±è°æˆåˆ†
        decay_factor = np.exp(-5 * t)
        audio += self.piano_config.inharmonic_amplitude * decay_factor * np.sin(2 * np.pi * inharmonic_freq * t)
        
        return audio
    
    def _add_soundboard_resonance(self, t: np.ndarray, frequency: float) -> np.ndarray:
        """æ·»åŠ éŸ³æ¿å…±é¸£"""
        audio = np.zeros_like(t, dtype=np.float64)
        
        # éŸ³æ¿å…±é¸£é¢‘ç‡ï¼ˆç•¥ä½äºåŸºé¢‘ï¼‰
        resonance_freq = frequency / (2 ** (self.piano_config.soundboard_freq_offset / 12))
        
        # å…±é¸£è¡°å‡ï¼ˆæ¯”ä¸»éŸ³å¿«ï¼‰
        decay_factor = np.exp(-4 * t)
        audio += self.piano_config.soundboard_resonance * decay_factor * np.sin(2 * np.pi * resonance_freq * t)
        
        return audio
    
    def _add_string_coupling(self, t: np.ndarray, frequency: float) -> np.ndarray:
        """æ·»åŠ ç´å¼¦è€¦åˆæ•ˆåº”"""
        audio = np.zeros_like(t, dtype=np.float64)
        
        # æ¨¡æ‹Ÿç›¸é‚»ç´å¼¦çš„é¢‘ç‡
        coupling_freq1 = frequency * 2.01  # ç•¥é«˜äºäºŒæ¬¡æ³›éŸ³
        coupling_freq2 = frequency * 3.02  # ç•¥é«˜äºä¸‰æ¬¡æ³›éŸ³
        
        # è€¦åˆæ•ˆåº”ï¼ˆå¿«é€Ÿè¡°å‡ï¼‰
        decay_factor = np.exp(-6 * t)
        audio += self.piano_config.string_coupling * decay_factor * np.sin(2 * np.pi * coupling_freq1 * t)
        audio += self.piano_config.string_coupling * 0.7 * decay_factor * np.sin(2 * np.pi * coupling_freq2 * t)
        
        return audio
    
    def _adjust_envelope_for_pitch(self, midi_number: int) -> EnvelopeConfig:
        """æ ¹æ®éŸ³é«˜è°ƒæ•´åŒ…ç»œ"""
        envelope = EnvelopeConfig(
            attack=self.piano_config.envelope.attack,
            decay=self.piano_config.envelope.decay,
            sustain=self.piano_config.envelope.sustain,
            release=self.piano_config.envelope.release
        )
        
        # ä½éŸ³åŒºï¼šç¼“æ…¢èµ·éŸ³ï¼Œé•¿é‡Šæ”¾
        if midi_number < 40:
            envelope.attack = min(0.01, envelope.attack * 1.5)
            envelope.release *= 1.3
            envelope.sustain *= 0.9
        # é«˜éŸ³åŒºï¼šå¿«é€Ÿèµ·éŸ³ï¼ŒçŸ­é‡Šæ”¾
        elif midi_number > 80:
            envelope.attack = max(0.001, envelope.attack * 0.7)
            envelope.release *= 0.6
            envelope.sustain *= 0.8
        
        return envelope
    
    def _calculate_dynamic_cutoff(self, midi_number: int, frequency: float) -> float:
        """æ ¹æ®éŸ³é«˜è®¡ç®—åŠ¨æ€æ»¤æ³¢å™¨æˆªæ­¢é¢‘ç‡"""
        # åŸºæœ¬æˆªæ­¢é¢‘ç‡ï¼šé¢‘ç‡è¶Šé«˜ï¼Œæ»¤æ³¢å™¨è¶Šå¼€æ”¾
        base_cutoff = frequency * 8
        
        # å¯¹ä¸­é«˜é¢‘è¿›è¡Œæ›´å¼ºçš„æ»¤æ³¢
        if midi_number > 60:
            cutoff_factor = 1.0 - ((midi_number - 60) / 48) * 0.3
            base_cutoff *= cutoff_factor
        
        # é™åˆ¶æœ€å¤§æˆªæ­¢é¢‘ç‡
        max_cutoff = self.config.sample_rate * 0.45
        return min(base_cutoff, max_cutoff)


# ============================================================================
# é€šç”¨ä¹å™¨ç”Ÿæˆå™¨ï¼ˆä½¿ç”¨FluidSynthï¼‰
# ============================================================================

class UniversalInstrumentGenerator(AudioGenerator):
    """é€šç”¨ä¹å™¨ç”Ÿæˆå™¨ï¼ˆä½¿ç”¨FluidSynthï¼‰"""
    
    def __init__(self, config: AudioConfig, instrument_type: InstrumentType, fs_generator=None):
        """
        åˆå§‹åŒ–é€šç”¨ä¹å™¨ç”Ÿæˆå™¨
        
        Args:
            config: éŸ³é¢‘é…ç½®
            instrument_type: ä¹å™¨ç±»å‹
            fs_generator: å¯é€‰çš„FluidSynthç”Ÿæˆå™¨å®ä¾‹ï¼ˆç”¨äºå…±äº«å®ä¾‹ï¼‰
        """
        super().__init__(config)
        self.instrument_type = instrument_type
        self.fs_generator = fs_generator
        self._initialized = False
    
    def _initialize(self):
        """å»¶è¿Ÿåˆå§‹åŒ–FluidSynthï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰"""
        if self._initialized:
            return
        
        if not HAS_FLUIDSYNTH:
            raise ImportError("æœªå®‰è£…FluidSynthã€‚è¯·ä½¿ç”¨pip install pyfluidsynthå®‰è£…")
        
        if self.fs_generator is None:
            # æŸ¥æ‰¾æˆ–ä¸‹è½½SoundFont
            soundfont_path = find_soundfont()
            if not soundfont_path:
                soundfont_dir = Path.home() / '.soundfonts'
                soundfont_path = download_soundfont(soundfont_dir)
            
            # åˆ›å»ºFluidSynthé…ç½®
            fs_config = FluidSynthConfig(
                sample_rate=self.config.sample_rate,
                soundfont_path=str(soundfont_path),
                gain=1.0,
                reverb=True,
                chorus=False
            )
            
            # åˆ›å»ºFluidSynthç”Ÿæˆå™¨
            self.fs_generator = FluidSynthGenerator(self.config, fs_config)
        
        self._initialized = True
    
    def generate(self, midi_number: int, velocity: float = 0.8, duration: float = None) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆä¹å™¨éŸ³ç¬¦"""
        self._initialize()
        
        if duration is None:
            duration = INSTRUMENT_DURATION[self.instrument_type]
        
        audio, sr = self.fs_generator.generate_note(
            self.instrument_type, midi_number, velocity, duration
        )
        
        return audio, sr


# ============================================================================
# èŠ‚æ‹å™¨ç”Ÿæˆå™¨
# ============================================================================

class MetronomeGenerator(AudioGenerator):
    """èŠ‚æ‹å™¨éŸ³æ•ˆç”Ÿæˆå™¨"""
    
    def __init__(self, config: AudioConfig, metronome_config: MetronomeConfig):
        super().__init__(config)
        self.metronome_config = metronome_config
    
    def generate(self, is_strong: bool = True) -> Tuple[np.ndarray, int]:
        """ç”ŸæˆèŠ‚æ‹å™¨éŸ³æ•ˆ"""
        # é€‰æ‹©é¢‘ç‡
        freq = self.metronome_config.strong_beat_freq if is_strong else self.metronome_config.weak_beat_freq
        
        # ç”Ÿæˆæ—¶é—´æ•°ç»„
        t = self._create_time_array(self.metronome_config.duration)
        
        # ç”ŸæˆåŸºæœ¬éŸ³è°ƒï¼ˆæ­£å¼¦æ³¢ï¼‰
        audio = np.sin(2 * np.pi * freq * t)
        
        # åº”ç”¨æ‰“å‡»ä¹åŒ…ç»œ
        envelope = EnvelopeGenerator.percussive(
            len(t), self.config.sample_rate, 1, self.metronome_config.decay_rate
        )
        audio *= envelope
        
        # åº”ç”¨ä½é€šæ»¤æ³¢
        audio = self.processor.lowpass_filter(
            audio, self.metronome_config.lowpass_cutoff, self.config.sample_rate
        )
        
        # å½’ä¸€åŒ–
        audio = self.processor.normalize(audio, 0.95)
        audio_int16 = self.processor.to_int16(audio)
        
        return audio_int16, self.config.sample_rate


# ============================================================================
# æ•ˆæœéŸ³ç”Ÿæˆå™¨
# ============================================================================

class EffectGenerator(AudioGenerator):
    """æ•ˆæœéŸ³ç”Ÿæˆå™¨"""
    
    def __init__(self, config: AudioConfig):
        super().__init__(config)
    
    def generate(self, effect_type: EffectType) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆæ•ˆæœéŸ³"""
        if effect_type == EffectType.CORRECT:
            return self._generate_correct()
        elif effect_type == EffectType.WRONG:
            return self._generate_wrong()
        elif effect_type == EffectType.COMPLETE:
            return self._generate_complete()
        elif effect_type == EffectType.LEVEL_UP:
            return self._generate_level_up()
        else:
            raise ValueError(f"æœªçŸ¥çš„æ•ˆæœéŸ³ç±»å‹: {effect_type}")
    
    def _generate_correct(self) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆå›ç­”æ­£ç¡®éŸ³æ•ˆ"""
        duration = 0.5
        t = self._create_time_array(duration)
        
        # ä¸Šå‡çš„å’Œå¼¦
        audio = np.sin(2 * np.pi * 523.25 * t)  # C5
        audio += 0.7 * np.sin(2 * np.pi * 659.26 * t)  # E5
        audio += 0.5 * np.sin(2 * np.pi * 783.99 * t)  # G5
        
        # åº”ç”¨åŒ…ç»œ
        envelope = np.exp(-5 * t)
        audio *= envelope
        
        # åº”ç”¨æ·¡å…¥æ·¡å‡º
        audio = self.processor.apply_fade(audio, int(0.01 * self.config.sample_rate), int(0.1 * self.config.sample_rate))
        
        # å½’ä¸€åŒ–
        audio = self.processor.normalize(audio, 0.95)
        audio_int16 = self.processor.to_int16(audio)
        
        return audio_int16, self.config.sample_rate
    
    def _generate_wrong(self) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆå›ç­”é”™è¯¯éŸ³æ•ˆ"""
        duration = 0.5
        t = self._create_time_array(duration)
        
        # ä¸‹é™çš„ä¸å’Œè°éŸ³ç¨‹
        audio = np.sin(2 * np.pi * 392.00 * t)  # G4
        audio += 0.7 * np.sin(2 * np.pi * 415.30 * t)  # G#4/Ab4
        
        # åº”ç”¨åŒ…ç»œ
        envelope = np.exp(-8 * t)
        audio *= envelope
        
        # åº”ç”¨æ·¡å…¥æ·¡å‡º
        audio = self.processor.apply_fade(audio, int(0.01 * self.config.sample_rate), int(0.1 * self.config.sample_rate))
        
        # å½’ä¸€åŒ–
        audio = self.processor.normalize(audio, 0.95)
        audio_int16 = self.processor.to_int16(audio)
        
        return audio_int16, self.config.sample_rate
    
    def _generate_complete(self) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆè®­ç»ƒå®ŒæˆéŸ³æ•ˆ"""
        duration = 1.0
        t = self._create_time_array(duration)
        
        # ä¸Šå‡çš„ç¶éŸ³
        audio = np.zeros_like(t)
        
        # Cå¤§è°ƒä¸Šè¡Œç¶éŸ³
        notes = [261.63, 329.63, 392.00, 523.25]  # C4, E4, G4, C5
        note_duration = duration / len(notes)
        
        for i, note in enumerate(notes):
            start = int(i * note_duration * self.config.sample_rate)
            end = int((i + 1) * note_duration * self.config.sample_rate)
            if end > len(t):
                end = len(t)
            
            t_segment = np.linspace(0, note_duration, end - start)
            segment = np.sin(2 * np.pi * note * t_segment)
            
            # åº”ç”¨åŒ…ç»œ
            env = np.exp(-3 * t_segment / note_duration)
            segment *= env
            
            audio[start:end] += segment
        
        # åº”ç”¨æ·¡å…¥æ·¡å‡º
        audio = self.processor.apply_fade(audio, int(0.01 * self.config.sample_rate), int(0.1 * self.config.sample_rate))
        
        # å½’ä¸€åŒ–
        audio = self.processor.normalize(audio, 0.95)
        audio_int16 = self.processor.to_int16(audio)
        
        return audio_int16, self.config.sample_rate
    
    def _generate_level_up(self) -> Tuple[np.ndarray, int]:
        """ç”Ÿæˆç­‰çº§æå‡éŸ³æ•ˆ"""
        duration = 1.2
        t = self._create_time_array(duration)
        
        # ä¸Šå‡çš„å’Œå¼¦è¿›è¡Œ
        audio = np.zeros_like(t)
        
        # åˆ†æˆä¸¤ä¸ªéƒ¨åˆ†
        half = int(len(t) / 2)
        
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šFå’Œå¼¦
        t1 = t[:half]
        chord1 = np.sin(2 * np.pi * 349.23 * t1)  # F4
        chord1 += 0.7 * np.sin(2 * np.pi * 440.00 * t1)  # A4
        chord1 += 0.5 * np.sin(2 * np.pi * 523.25 * t1)  # C5
        
        # ç¬¬äºŒéƒ¨åˆ†ï¼šGå’Œå¼¦
        t2 = t[half:]
        chord2 = np.sin(2 * np.pi * 392.00 * t2)  # G4
        chord2 += 0.7 * np.sin(2 * np.pi * 493.88 * t2)  # B4
        chord2 += 0.5 * np.sin(2 * np.pi * 587.33 * t2)  # D5
        
        # åº”ç”¨åŒ…ç»œ
        env1 = np.exp(-2 * t1 / (duration/2))
        env2 = np.exp(-1 * t2 / (duration/2))
        chord1 *= env1
        chord2 *= env2
        
        # ç»„åˆ
        audio[:half] = chord1
        audio[half:] = chord2
        
        # åº”ç”¨æ·¡å…¥æ·¡å‡º
        audio = self.processor.apply_fade(audio, int(0.01 * self.config.sample_rate), int(0.1 * self.config.sample_rate))
        
        # å½’ä¸€åŒ–
        audio = self.processor.normalize(audio, 0.95)
        audio_int16 = self.processor.to_int16(audio)
        
        return audio_int16, self.config.sample_rate


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

class AudioGenerationApp:
    """éŸ³é¢‘ç”Ÿæˆåº”ç”¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.config = AudioConfig(sample_rate=44100, bit_depth=16, channels=1)
        self.output_dir = Path("audio_output")  # é»˜è®¤è¾“å‡ºç›®å½•
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–FluidSynthç”Ÿæˆå™¨ï¼ˆå…±äº«å®ä¾‹ï¼‰
        self.fs_generator = None
        if HAS_FLUIDSYNTH:
            try:
                # æŸ¥æ‰¾æˆ–ä¸‹è½½SoundFont
                soundfont_path = find_soundfont()
                if not soundfont_path:
                    soundfont_dir = Path.home() / '.soundfonts'
                    soundfont_path = download_soundfont(soundfont_dir)
                
                # åˆ›å»ºFluidSynthé…ç½®
                fs_config = FluidSynthConfig(
                    sample_rate=self.config.sample_rate,
                    soundfont_path=str(soundfont_path),
                    gain=1.0,
                    reverb=True,
                    chorus=False
                )
                
                # åˆ›å»ºFluidSynthç”Ÿæˆå™¨
                self.fs_generator = FluidSynthGenerator(self.config, fs_config)
            except Exception as e:
                print(f"âŒ FluidSynthåˆå§‹åŒ–å¤±è´¥: {e}")
                print("   å°†ä½¿ç”¨å¤‡ç”¨ç”Ÿæˆå™¨")
                self.fs_generator = None
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨å·¥å‚
        self.generator_factory = GeneratorFactory(self.config, self.fs_generator)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.fs_generator is not None:
            self.fs_generator.cleanup()
    
    def generate_notes(self, instrument_type: InstrumentType, 
                      duration: Optional[float] = None, 
                      analyze_audio: bool = False,
                      parallel: bool = False):
        """ç”ŸæˆéŸ³ç¬¦"""
        print(f"\nğŸµ æ­£åœ¨ç”Ÿæˆ{INSTRUMENT_NAMES_CN[instrument_type]}éŸ³ç¬¦...")
        
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = self.generator_factory.create_generator(instrument_type)
        
        # åˆ›å»ºè¾“å‡ºå­ç›®å½•
        instrument_dir = self.output_dir / instrument_type.name.lower()
        instrument_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ†æç›®å½•
        if analyze_audio:
            analysis_dir = instrument_dir / "analysis"
            analysis_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ‰€æœ‰éŸ³ç¬¦
        if parallel and cpu_count() > 1:
            self._generate_notes_parallel(generator, instrument_type, instrument_dir, 
                                         duration, analyze_audio, analysis_dir if analyze_audio else None)
        else:
            self._generate_notes_sequential(generator, instrument_type, instrument_dir, 
                                           duration, analyze_audio, analysis_dir if analyze_audio else None)
    
    def _generate_notes_sequential(self, generator, instrument_type, output_dir, 
                                  duration, analyze_audio, analysis_dir=None):
        """é¡ºåºç”ŸæˆéŸ³ç¬¦"""
        notes_to_generate = list(MIDI_RANGE)
        total_notes = len(notes_to_generate)
        
        # ä½¿ç”¨tqdmè¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if HAS_TQDM:
            iterator = tqdm(enumerate(notes_to_generate), total=total_notes, desc="ç”ŸæˆéŸ³ç¬¦")
        else:
            iterator = enumerate(notes_to_generate)
            print(f"æ€»å…±éœ€è¦ç”Ÿæˆ {total_notes} ä¸ªéŸ³ç¬¦...")
        
        for i, midi_number in iterator:
            progress = (i + 1) / total_notes * 100
            
            # ç”ŸæˆéŸ³ç¬¦
            note_name = midi_to_note_name(midi_number)
            output_file = output_dir / f"{midi_number}_{note_name}.wav"
            
            if not output_file.exists():
                # ç”ŸæˆéŸ³é¢‘
                audio, sr = generator.generate(midi_number, velocity=0.8, duration=duration)
                
                # ä¿å­˜éŸ³é¢‘
                self._save_audio(audio, sr, output_file)
                
                # åˆ†æéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
                if analyze_audio and midi_number in SAMPLE_NOTES_FOR_ANALYSIS:
                    analysis_file = analysis_dir / f"{midi_number}_{note_name}_analysis.png"
                    AudioVisualizer.plot_analysis(audio, sr, midi_number, analysis_file)
            
            # ä¸ä½¿ç”¨tqdmæ—¶ï¼Œæ¯10ä¸ªéŸ³ç¬¦æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if not HAS_TQDM and (i+1) % 10 == 0:
                print(f"è¿›åº¦: {progress:.1f}% ({i+1}/{total_notes})")
    
    def _generate_notes_parallel(self, generator, instrument_type, output_dir, 
                                duration, analyze_audio, analysis_dir=None):
        """å¹¶è¡Œç”ŸæˆéŸ³ç¬¦"""
        notes_to_generate = []
        for midi_number in MIDI_RANGE:
            note_name = midi_to_note_name(midi_number)
            output_file = output_dir / f"{midi_number}_{note_name}.wav"
            if not output_file.exists():
                notes_to_generate.append((midi_number, note_name, output_file))
        
        total_notes = len(notes_to_generate)
        if total_notes == 0:
            print("âœ“ æ‰€æœ‰éŸ³ç¬¦å·²ç”Ÿæˆï¼Œæ— éœ€é‡æ–°ç”Ÿæˆ")
            return
        
        print(f"éœ€è¦ç”Ÿæˆ {total_notes} ä¸ªéŸ³ç¬¦ï¼Œå°†ä½¿ç”¨å¹¶è¡Œå¤„ç†...")
        
        # ç¡®å®šè¿›ç¨‹æ•°ï¼ˆä½¿ç”¨CPUæ ¸å¿ƒæ•°çš„75%ï¼Œæœ€å°‘2ä¸ªï¼Œæœ€å¤š16ä¸ªï¼‰
        num_processes = max(2, min(16, int(cpu_count() * 0.75)))
        print(f"ä½¿ç”¨ {num_processes} ä¸ªå¹¶è¡Œè¿›ç¨‹")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜å‚¨SoundFont
        with tempfile.TemporaryDirectory() as temp_dir:
            # å¦‚æœæœ‰SoundFontï¼Œå¤åˆ¶åˆ°ä¸´æ—¶ç›®å½•ä»¥ä¾¿å­è¿›ç¨‹ä½¿ç”¨
            if self.fs_generator and hasattr(self.fs_generator, 'fs_config'):
                soundfont_path = Path(self.fs_generator.fs_config.soundfont_path)
                if soundfont_path.exists():
                    temp_sf_path = Path(temp_dir) / soundfont_path.name
                    shutil.copy(soundfont_path, temp_sf_path)
                    os.environ['SOUNDFONT'] = str(temp_sf_path)
            
            # åˆ›å»ºä»»åŠ¡
            tasks = []
            for midi_number, note_name, output_file in notes_to_generate:
                tasks.append((
                    instrument_type.name, 
                    midi_number,
                    str(output_file),
                    duration,
                    analyze_audio and midi_number in SAMPLE_NOTES_FOR_ANALYSIS,
                    str(analysis_dir) if analysis_dir else None
                ))
            
            # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†
            with Pool(processes=num_processes) as pool:
                if HAS_TQDM:
                    from tqdm import tqdm
                    list(tqdm(pool.imap(_process_note_task, tasks), 
                             total=len(tasks), desc="ç”ŸæˆéŸ³ç¬¦"))
                else:
                    results = []
                    for i, _ in enumerate(pool.imap_unordered(_process_note_task, tasks)):
                        results.append(_)
                        if (i+1) % 5 == 0 or (i+1) == total_notes:
                            progress = (i+1) / total_notes * 100
                            print(f"è¿›åº¦: {progress:.1f}% ({i+1}/{total_notes})")
    
    def generate_metronome(self):
        """ç”ŸæˆèŠ‚æ‹å™¨éŸ³æ•ˆ"""
        print("\nğŸµ æ­£åœ¨ç”ŸæˆèŠ‚æ‹å™¨éŸ³æ•ˆ...")
        
        # åˆ›å»ºè¾“å‡ºå­ç›®å½•
        metronome_dir = self.output_dir / "metronome"
        metronome_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºèŠ‚æ‹å™¨ç”Ÿæˆå™¨
        metronome_config = MetronomeConfig()
        generator = MetronomeGenerator(self.config, metronome_config)
        
        # ç”Ÿæˆå¼ºæ‹éŸ³æ•ˆ
        strong_beat_file = metronome_dir / "strong_beat.wav"
        if not strong_beat_file.exists():
            audio, sr = generator.generate(is_strong=True)
            self._save_audio(audio, sr, strong_beat_file)
            print(f"âœ“ ç”Ÿæˆå¼ºæ‹éŸ³æ•ˆ: {strong_beat_file}")
        
        # ç”Ÿæˆå¼±æ‹éŸ³æ•ˆ
        weak_beat_file = metronome_dir / "weak_beat.wav"
        if not weak_beat_file.exists():
            audio, sr = generator.generate(is_strong=False)
            self._save_audio(audio, sr, weak_beat_file)
            print(f"âœ“ ç”Ÿæˆå¼±æ‹éŸ³æ•ˆ: {weak_beat_file}")
    
    def generate_effects(self):
        """ç”Ÿæˆæ•ˆæœéŸ³"""
        print("\nğŸµ æ­£åœ¨ç”Ÿæˆæ•ˆæœéŸ³...")
        
        # åˆ›å»ºè¾“å‡ºå­ç›®å½•
        effects_dir = self.output_dir / "effects"
        effects_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ•ˆæœéŸ³ç”Ÿæˆå™¨
        generator = EffectGenerator(self.config)
        
        # ç”Ÿæˆæ‰€æœ‰æ•ˆæœéŸ³
        for effect_type in EffectType:
            effect_file = effects_dir / f"{effect_type.value}.wav"
            if not effect_file.exists():
                audio, sr = generator.generate(effect_type)
                self._save_audio(audio, sr, effect_file)
                print(f"âœ“ ç”Ÿæˆæ•ˆæœéŸ³: {effect_file}")
    
    def _save_audio(self, audio: np.ndarray, sr: int, output_file: Path):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        if HAS_SOUNDFILE:
            # ä½¿ç”¨soundfileä¿å­˜ï¼ˆæ›´å¥½çš„WAVæ–‡ä»¶æ”¯æŒï¼‰
            sf.write(str(output_file), audio, sr, subtype='PCM_16')
        else:
            # ä½¿ç”¨scipy.io.wavfileä¿å­˜
            wavfile.write(str(output_file), sr, audio)


class GeneratorFactory:
    """ç”Ÿæˆå™¨å·¥å‚"""
    
    def __init__(self, config: AudioConfig, fs_generator=None):
        self.config = config
        self.fs_generator = fs_generator
    
    def create_generator(self, instrument_type: InstrumentType) -> AudioGenerator:
        """åˆ›å»ºéŸ³é¢‘ç”Ÿæˆå™¨"""
        # å¦‚æœæœ‰FluidSynthï¼Œä½¿ç”¨FluidSynthç”Ÿæˆ
        if HAS_FLUIDSYNTH and self.fs_generator is not None:
            return UniversalInstrumentGenerator(self.config, instrument_type, self.fs_generator)
        
        # å¦åˆ™ä½¿ç”¨å¤‡ç”¨ç”Ÿæˆå™¨
        if instrument_type == InstrumentType.PIANO:
            piano_config = EnhancedPianoConfig()
            return EnhancedPianoGenerator(self.config, piano_config)
        else:
            # å¯¹äºå…¶ä»–ä¹å™¨ï¼Œä»å°è¯•ä½¿ç”¨FluidSynthï¼ˆå¯èƒ½ä¼šè§¦å‘å»¶è¿Ÿåˆå§‹åŒ–ï¼‰
            try:
                return UniversalInstrumentGenerator(self.config, instrument_type)
            except ImportError:
                # å¦‚æœFluidSynthä¸å¯ç”¨ï¼Œå›é€€åˆ°å¢å¼ºé’¢ç´
                print(f"âš ï¸ è­¦å‘Š: FluidSynthä¸å¯ç”¨ï¼Œ{INSTRUMENT_NAMES_CN[instrument_type]}å°†ä½¿ç”¨å¢å¼ºé’¢ç´ä»£æ›¿")
                piano_config = EnhancedPianoConfig(duration=INSTRUMENT_DURATION[instrument_type])
                return EnhancedPianoGenerator(self.config, piano_config)


def _process_note_task(task):
    """å¤„ç†å•ä¸ªéŸ³ç¬¦ä»»åŠ¡ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
    instrument_name, midi_number, output_file, duration, do_analysis, analysis_dir = task
    
    try:
        # åˆ›å»ºé…ç½®
        config = AudioConfig(sample_rate=44100, bit_depth=16, channels=1)
        
        # è·å–ä¹å™¨ç±»å‹
        instrument_type = InstrumentType[instrument_name]
        
        # åˆ›å»ºç”Ÿæˆå™¨
        if HAS_FLUIDSYNTH:
            try:
                generator = UniversalInstrumentGenerator(config, instrument_type)
            except Exception:
                piano_config = EnhancedPianoConfig(duration=INSTRUMENT_DURATION[instrument_type])
                generator = EnhancedPianoGenerator(config, piano_config)
        else:
            piano_config = EnhancedPianoConfig(duration=INSTRUMENT_DURATION[instrument_type])
            generator = EnhancedPianoGenerator(config, piano_config)
        
        # ç”ŸæˆéŸ³é¢‘
        audio, sr = generator.generate(midi_number, velocity=0.8, duration=duration)
        
        # ä¿å­˜éŸ³é¢‘
        if HAS_SOUNDFILE:
            sf.write(output_file, audio, sr, subtype='PCM_16')
        else:
            wavfile.write(output_file, sr, audio)
        
        # åˆ†æéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
        if do_analysis and analysis_dir:
            note_name = midi_to_note_name(midi_number)
            analysis_file = Path(analysis_dir) / f"{midi_number}_{note_name}_analysis.png"
            AudioVisualizer.plot_analysis(audio, sr, midi_number, analysis_file)
        
        return True
    except Exception as e:
        print(f"âŒ å¤„ç†MIDIéŸ³ç¬¦{midi_number}æ—¶å‡ºé”™: {e}")
        return False


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="éŸ³é¢‘ç”Ÿæˆè„šæœ¬")
    parser.add_argument("--instrument", "-i", type=str, default="piano",
                        help="è¦ç”Ÿæˆçš„ä¹å™¨ç±»å‹ (piano, electric_piano, organ, strings, pad, bell, bass, pluck)")
    parser.add_argument("--duration", "-d", type=float,
                        help="éŸ³ç¬¦æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--analyze", "-a", action="store_true",
                        help="ç”ŸæˆéŸ³é¢‘åˆ†æå›¾è¡¨")
    parser.add_argument("--parallel", "-p", action="store_true",
                        help="ä½¿ç”¨å¹¶è¡Œå¤„ç†")
    parser.add_argument("--output", "-o", type=str, default="audio_output",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--metronome", "-m", action="store_true",
                        help="ç”ŸæˆèŠ‚æ‹å™¨éŸ³æ•ˆ")
    parser.add_argument("--effects", "-e", action="store_true",
                        help="ç”Ÿæˆæ•ˆæœéŸ³")
    parser.add_argument("--all", action="store_true",
                        help="ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘")
    parser.add_argument("--list-instruments", "-l", action="store_true",
                        help="åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„ä¹å™¨")
    parser.add_argument("--download-soundfont", action="store_true",
                        help="ä¸‹è½½é«˜è´¨é‡éŸ³è‰²åº“")
    
    args = parser.parse_args()
    
    # åˆ—å‡ºä¹å™¨
    if args.list_instruments:
        list_instruments()
        return
    
    # ä¸‹è½½éŸ³è‰²åº“
    if args.download_soundfont:
        soundfont_dir = Path.home() / '.soundfonts'
        download_soundfont(soundfont_dir)
        return
    
    start_time = time.time()
    
    try:
        # åˆ›å»ºåº”ç”¨å®ä¾‹
        app = AudioGenerationApp()
        app.output_dir = Path(args.output)
        
        # ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘
        if args.all:
            for instrument_name in INSTRUMENT_NAME_MAP:
                instrument_type = get_instrument_type(instrument_name)
                app.generate_notes(instrument_type, args.duration, args.analyze, args.parallel)
            app.generate_metronome()
            app.generate_effects()
        else:
            # ç”ŸæˆæŒ‡å®šä¹å™¨çš„éŸ³ç¬¦
            if not args.metronome and not args.effects:
                try:
                    instrument_type = get_instrument_type(args.instrument)
                    app.generate_notes(instrument_type, args.duration, args.analyze, args.parallel)
                except ValueError as e:
                    print(f"âŒ é”™è¯¯: {e}")
                    return
            
            # ç”ŸæˆèŠ‚æ‹å™¨éŸ³æ•ˆ
            if args.metronome:
                app.generate_metronome()
            
            # ç”Ÿæˆæ•ˆæœéŸ³
            if args.effects:
                app.generate_effects()
    
    finally:
        # æ¸…ç†èµ„æº
        if 'app' in locals():
            app.cleanup()
    
    # æ˜¾ç¤ºæ€»è€—æ—¶
    elapsed_time = time.time() - start_time
    minutes = int(elapsed_time // 60)
    seconds = int(elapsed_time % 60)
    print(f"\nâœ¨ å®Œæˆ! æ€»è€—æ—¶: {minutes}åˆ†{seconds}ç§’")


if __name__ == "__main__":
    main()

